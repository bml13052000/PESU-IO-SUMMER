{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RISK_MM</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>1.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>0.2</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  \\\n",
       "0  2008-12-01   Albury     13.4     22.9       0.6          NaN       NaN   \n",
       "1  2008-12-02   Albury      7.4     25.1       0.0          NaN       NaN   \n",
       "2  2008-12-03   Albury     12.9     25.7       0.0          NaN       NaN   \n",
       "3  2008-12-04   Albury      9.2     28.0       0.0          NaN       NaN   \n",
       "4  2008-12-05   Albury     17.5     32.3       1.0          NaN       NaN   \n",
       "\n",
       "  WindGustDir  WindGustSpeed WindDir9am  ... Humidity3pm  Pressure9am  \\\n",
       "0           W           44.0          W  ...        22.0       1007.7   \n",
       "1         WNW           44.0        NNW  ...        25.0       1010.6   \n",
       "2         WSW           46.0          W  ...        30.0       1007.6   \n",
       "3          NE           24.0         SE  ...        16.0       1017.6   \n",
       "4           W           41.0        ENE  ...        33.0       1010.8   \n",
       "\n",
       "   Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  RISK_MM  \\\n",
       "0       1007.1       8.0       NaN     16.9     21.8         No      0.0   \n",
       "1       1007.8       NaN       NaN     17.2     24.3         No      0.0   \n",
       "2       1008.7       NaN       2.0     21.0     23.2         No      0.0   \n",
       "3       1012.8       NaN       NaN     18.1     26.5         No      1.0   \n",
       "4       1006.0       7.0       8.0     17.8     29.7         No      0.2   \n",
       "\n",
       "   RainTomorrow  \n",
       "0            No  \n",
       "1            No  \n",
       "2            No  \n",
       "3            No  \n",
       "4            No  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Sunshine','Evaporation','Cloud3pm','Cloud9am','Location','RISK_MM','Date', 'RISK_MM'],axis=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(df, test_size = 0.2, random_state = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set.drop(\"RainToday\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting cateogrical to numerical\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names=attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_set.drop(\"RainTomorrow\", axis = 1)\n",
    "y = train_set[\"RainTomorrow\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing sklearn Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"select_cat\", DataFrameSelector([\"WindGustDir\", \"WindDir9am\", \"WindDir3pm\"])),\n",
    "        (\"imp\", SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse=False)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"MinTemp\", \"MaxTemp\", \"Rainfall\", \"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\", \"Humidity9am\", \"Humidity3pm\",\n",
    "                                              \"Pressure9am\", \"Pressure3pm\", \"Temp9am\", \"Temp3pm\"])),\n",
    "        (\"imp\", SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ])\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical data into numerical data using dictonary method\n",
    "X_train_prepared = preprocess_pipeline.fit_transform(X)\n",
    "y_train_prepared = y.map({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_set.drop(\"RainTomorrow\", axis = 1)\n",
    "y_test = test_set[\"RainTomorrow\"].copy()\n",
    "\n",
    "X_test_prepared = preprocess_pipeline.fit_transform(X_test)\n",
    "y_test_prepared = y_test.map({'Yes':1, 'No':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model with adam optimizer\n",
      "Epoch 1/1\n",
      "113754/113754 [==============================] - 7s 64us/step - loss: 0.3624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f568a672cc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ann model that we learnt in lecture 5 using keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "n_cols =  X_train_prepared.shape[1]\n",
    "target =  to_categorical(y_train_prepared)\n",
    "\n",
    "def get_new_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = (n_cols,)))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model\n",
    "print(\"Testing model with adam optimizer\")\n",
    "model = get_new_model()\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy')\n",
    "model.fit(X_train_prepared, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 6s 71us/step - loss: 0.3686 - acc: 0.8403 - val_loss: 0.3542 - val_acc: 0.8466\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 5s 65us/step - loss: 0.3525 - acc: 0.8477 - val_loss: 0.3445 - val_acc: 0.8513\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 5s 66us/step - loss: 0.3452 - acc: 0.8513 - val_loss: 0.3432 - val_acc: 0.8528\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 5s 68us/step - loss: 0.3401 - acc: 0.8532 - val_loss: 0.3429 - val_acc: 0.8524\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 5s 68us/step - loss: 0.3364 - acc: 0.8546 - val_loss: 0.3415 - val_acc: 0.8534\n",
      "Epoch 6/20\n",
      "79627/79627 [==============================] - 5s 67us/step - loss: 0.3321 - acc: 0.8566 - val_loss: 0.3423 - val_acc: 0.8545\n",
      "Epoch 7/20\n",
      "79627/79627 [==============================] - 5s 68us/step - loss: 0.3278 - acc: 0.8575 - val_loss: 0.3450 - val_acc: 0.8511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56888efa58>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=2) \n",
    "\n",
    "# Without adding any nodes or layers\n",
    "model = get_new_model()\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 6s 75us/step - loss: 0.3673 - acc: 0.8401 - val_loss: 0.3517 - val_acc: 0.8484\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 6s 69us/step - loss: 0.3516 - acc: 0.8477 - val_loss: 0.3464 - val_acc: 0.8515\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 6s 71us/step - loss: 0.3449 - acc: 0.8513 - val_loss: 0.3415 - val_acc: 0.8520\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 6s 71us/step - loss: 0.3392 - acc: 0.8524 - val_loss: 0.3400 - val_acc: 0.8545\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 6s 76us/step - loss: 0.3341 - acc: 0.8552 - val_loss: 0.3432 - val_acc: 0.8521\n",
      "Epoch 6/20\n",
      "79627/79627 [==============================] - 5s 67us/step - loss: 0.3290 - acc: 0.8581 - val_loss: 0.3418 - val_acc: 0.8532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f56811e6710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we are increasing the no of layers to decrease the loss \n",
    "model = Sequential()\n",
    "model.add(Dense(120, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 7s 94us/step - loss: 0.3674 - acc: 0.8403 - val_loss: 0.3556 - val_acc: 0.8444\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 7s 90us/step - loss: 0.3523 - acc: 0.8474 - val_loss: 0.3451 - val_acc: 0.8508\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 7s 84us/step - loss: 0.3450 - acc: 0.8503 - val_loss: 0.3467 - val_acc: 0.8499\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 7s 83us/step - loss: 0.3395 - acc: 0.8529 - val_loss: 0.3407 - val_acc: 0.8540\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 7s 86us/step - loss: 0.3341 - acc: 0.8558 - val_loss: 0.3495 - val_acc: 0.8507\n",
      "Epoch 6/20\n",
      "79627/79627 [==============================] - 7s 84us/step - loss: 0.3284 - acc: 0.8574 - val_loss: 0.3447 - val_acc: 0.8520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5680ea3828>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#same as above\n",
    "model = Sequential()\n",
    "model.add(Dense(120, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79627 samples, validate on 34127 samples\n",
      "Epoch 1/20\n",
      "79627/79627 [==============================] - 6s 80us/step - loss: 0.3670 - acc: 0.8406 - val_loss: 0.3505 - val_acc: 0.8471\n",
      "Epoch 2/20\n",
      "79627/79627 [==============================] - 6s 74us/step - loss: 0.3523 - acc: 0.8475 - val_loss: 0.3496 - val_acc: 0.8500\n",
      "Epoch 3/20\n",
      "79627/79627 [==============================] - 6s 75us/step - loss: 0.3451 - acc: 0.8519 - val_loss: 0.3430 - val_acc: 0.8519\n",
      "Epoch 4/20\n",
      "79627/79627 [==============================] - 6s 73us/step - loss: 0.3398 - acc: 0.8539 - val_loss: 0.3475 - val_acc: 0.8542\n",
      "Epoch 5/20\n",
      "79627/79627 [==============================] - 6s 75us/step - loss: 0.3347 - acc: 0.8556 - val_loss: 0.3441 - val_acc: 0.8523\n",
      "113754/113754 [==============================] - 4s 31us/step\n",
      "Accuracy=  0.8574643529039719\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "model = Sequential()\n",
    "model.add(Dense(120, activation='relu', input_shape = (n_cols,)))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X_train_prepared, target, validation_split=0.3, epochs=20, callbacks = [early_stopping_monitor])\n",
    "#testing the data\n",
    "test_loss, test_acc = model.evaluate(X_train_prepared, target)\n",
    "print(\"Accuracy= \",test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
